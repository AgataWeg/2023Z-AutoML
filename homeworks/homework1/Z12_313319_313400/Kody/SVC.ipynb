{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from smac import HyperparameterOptimizationFacade, Scenario\n",
    "from ConfigSpace import Configuration, ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import CategoricalHyperparameter, UniformFloatHyperparameter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from Utils.dataManagingUtils import fetch_openml_dataset, prepare_data, save_data_to_csv, create_SVC_allDatasets_tuning_hisotry_object, create_SVC_tuning_hisotry_object, create_comparison_object\n",
    "from Utils.pipelineUtils import create_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "set_config(transform_output = \"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja stałych użytych w metodach samplingu \n",
    "n_jobs=-1\n",
    "n_iter_randomSearch= 300 # około 2h\n",
    "n_iter_bayes=150 # okolo 3h\n",
    "verbose=1\n",
    "random_state=42\n",
    "cv=5\n",
    "numberOfPoints=50\n",
    "\n",
    "# Wartości hiperparametrów\n",
    "cost_lower = 0.01\n",
    "cost_upper = 10.0\n",
    "kernel = ['linear', 'rbf', 'sigmoid']\n",
    "gamma_lower = 0.001\n",
    "gamma_upper = 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieranie danych\n",
    "m_t_beforePrepare = fetch_openml_dataset(44116)\n",
    "o_s_beforePrepare = fetch_openml_dataset(45560)\n",
    "b_m_beforePrepare = fetch_openml_dataset(44126)\n",
    "c_d_beforePrepare = fetch_openml_dataset(45024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obróbka Danych \n",
    "m_t_X, m_t_y = prepare_data(m_t_beforePrepare, 'class')\n",
    "o_s_X, o_s_y = prepare_data(o_s_beforePrepare, 'Revenue')\n",
    "b_m_X, b_m_y = prepare_data(b_m_beforePrepare, 'Class')\n",
    "c_d_X, c_d_y = prepare_data(c_d_beforePrepare, 'SeriousDlqin2yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział Danych \n",
    "m_t_X_train,   m_t_X_test, m_t_y_train, m_t_y_test = train_test_split(m_t_X , m_t_y,test_size=0.2)\n",
    "o_s_X_train,   o_s_X_test, o_s_y_train, o_s_y_test = train_test_split(o_s_X, o_s_y,test_size=0.2)\n",
    "b_m_X_train,   b_m_X_test, b_m_y_train, b_m_y_test = train_test_split(b_m_X, b_m_y,test_size=0.2)\n",
    "c_d_X_train,   c_d_X_test, c_d_y_train, c_d_y_test = train_test_split(c_d_X, c_d_y,test_size=0.2)\n",
    "\n",
    "X_train_list = [ m_t_X_train, o_s_X_train, b_m_X_train, c_d_X_train]\n",
    "y_train_list = [ m_t_y_train, o_s_y_train, b_m_y_train, c_d_y_train]\n",
    "X_test_list = [ m_t_X_test, o_s_X_test, b_m_X_test, c_d_X_test]\n",
    "y_test_list = [ m_t_y_test, o_s_y_test, b_m_y_test, c_d_y_test]\n",
    "file_names = [\"m_t_tuning_history\", \"o_s_tuning_history\", \"b_m_tuning_history\",\"c_d_tuning_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja tabel służących do przechowywania informacji o histori tuningu dla random Search, biorąc pod uwagę wszystkie datasety\n",
    "allDatasets_randomSearch_tunability_history = create_SVC_allDatasets_tuning_hisotry_object()\n",
    "helper = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC optymalizacja hiperparametrow uzywajac RandomizedSearchCV\n",
    "param_space = {\n",
    "    'model__C': np.linspace(cost_lower, cost_upper, numberOfPoints).astype(float),\n",
    "    'model__kernel': kernel,\n",
    "    'model__gamma':  np.linspace(gamma_lower, gamma_upper, numberOfPoints).astype(float),\n",
    "}\n",
    "\n",
    "SVClassifier_pipeline = Pipeline([\n",
    "    ('preprocessing', create_column_transformer()),\n",
    "    ('model', SVC())\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=SVClassifier_pipeline,\n",
    "    param_distributions=param_space,\n",
    "    n_jobs=n_jobs,\n",
    "    n_iter=n_iter_randomSearch,\n",
    "    verbose=verbose,\n",
    "    random_state=random_state,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "\n",
    "for file_name, X_train, y_train in zip(file_names, X_train_list, y_train_list):\n",
    "    random_search.fit(X_train, y_train)\n",
    "    cs_results = pd.DataFrame(random_search.cv_results_)\n",
    "    helper[f'{file_name}']=cs_results['mean_test_score']\n",
    "    save_data_to_csv(cs_results, f\"../Wyniki/SVC/RandomSearch/{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenie optymalnych hiperparametrow dla random search\n",
    "mean_column = helper.mean(axis=1)\n",
    "std_column = helper.std(axis=1)\n",
    "\n",
    "for i in range(len(cs_results)):\n",
    "    allDatasets_randomSearch_tunability_history['param_model__C'].append(cs_results['param_model__C'][i])\n",
    "    allDatasets_randomSearch_tunability_history['param_model__kernel'].append(cs_results['param_model__kernel'][i])\n",
    "    allDatasets_randomSearch_tunability_history['param_model__gamma'].append(cs_results['param_model__gamma'][i])\n",
    "    allDatasets_randomSearch_tunability_history['mean_all_datasets_test_score'].append(mean_column[i])\n",
    "    allDatasets_randomSearch_tunability_history['std_all_datasets_test_score'].append(std_column[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie optymalnych hiperparametrów dla Random Search\n",
    "allDatasets_randomSearch_tunability_history = pd.DataFrame(allDatasets_randomSearch_tunability_history)\n",
    "max_value = allDatasets_randomSearch_tunability_history['mean_all_datasets_test_score'].max()\n",
    "randomSearch_bestHyperParameter = allDatasets_randomSearch_tunability_history[allDatasets_randomSearch_tunability_history['mean_all_datasets_test_score'] == max_value]\n",
    "print(\"Optymalne hiperparametry:\", randomSearch_bestHyperParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis do plików historii tuningu dla Random Search \n",
    "save_data_to_csv(allDatasets_randomSearch_tunability_history, f\"../Wyniki/SVC/RandomSearch/allDatasets_tunability_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja tabel służących do przechowywania informacji o histori tuningu dla Bayes Optimization\n",
    "m_t_tunability_history = create_SVC_tuning_hisotry_object(cv)\n",
    "o_s_tunability_history = create_SVC_tuning_hisotry_object(cv)\n",
    "b_m_tunability_history = create_SVC_tuning_hisotry_object(cv)\n",
    "c_d_tunability_history = create_SVC_tuning_hisotry_object(cv)\n",
    "tunability_hisotry_list = [m_t_tunability_history,o_s_tunability_history,b_m_tunability_history, c_d_tunability_history]\n",
    "\n",
    "# Definicja tabel służących do przechowywania informacji o histori tuningu dla Bayes Optimization, biorąc pod uwagę wszystkie datasety\n",
    "allDatasets_BO_tunability_history = create_SVC_allDatasets_tuning_hisotry_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja tabel służących do przechowywania informacji o historii tuningu dla Bayes Optimization\n",
    "def svc_objective_function(config: Configuration, seed :int):\n",
    "    all_scores = []\n",
    "\n",
    "    cost = config['C']\n",
    "    kernel = config['kernel']\n",
    "    gamma = config['gamma']\n",
    "    print(f\"C:{cost}, kernel:{kernel}, gamma:{gamma}\\n\")\n",
    "    \n",
    "    allDatasets_BO_tunability_history['param_model__C'].append(cost)\n",
    "    allDatasets_BO_tunability_history['param_model__kernel'].append(kernel)  \n",
    "    allDatasets_BO_tunability_history['param_model__gamma'].append(gamma)  \n",
    "\n",
    "    for X_train, y_train, tunability_hisotry in zip(X_train_list, y_train_list, tunability_hisotry_list):\n",
    "        tunability_hisotry['param_model__C'].append(cost)\n",
    "        tunability_hisotry['param_model__kernel'].append(kernel)  \n",
    "        tunability_hisotry['param_model__gamma'].append(gamma)  \n",
    "\n",
    "        SVClassifier_pipeline = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', SVC(C=cost,kernel=kernel,gamma=gamma, random_state=seed))])\n",
    "        scores = cross_val_score(SVClassifier_pipeline, X_train, y_train, scoring='roc_auc', cv=cv)\n",
    "        for i in range(cv):\n",
    "            tunability_hisotry[f'split{i}_test_score'].append(scores[i])\n",
    "        tunability_hisotry['mean_test_score'].append(np.mean(scores))  \n",
    "        tunability_hisotry['std_test_score'].append(np.std(scores)) \n",
    "        all_scores.extend(scores)\n",
    "    \n",
    "    all_scores_mean = np.mean(all_scores)\n",
    "    all_scores_std = np.std(all_scores)\n",
    "    allDatasets_BO_tunability_history['mean_all_datasets_test_score'].append(all_scores_mean)  \n",
    "    allDatasets_BO_tunability_history['std_all_datasets_test_score'].append(all_scores_std)    \n",
    "    print(f\"all_scores_mean:{all_scores_mean}, all_scores_std:{all_scores_std}\\n\")\n",
    "    return -all_scores_mean\n",
    "\n",
    "configspace = ConfigurationSpace()\n",
    "configspace.add_hyperparameter(UniformFloatHyperparameter('C', lower=cost_lower, upper=cost_upper))\n",
    "configspace.add_hyperparameter(CategoricalHyperparameter('kernel', kernel))\n",
    "configspace.add_hyperparameter(UniformFloatHyperparameter('gamma', lower=gamma_lower, upper=gamma_upper))\n",
    "\n",
    "default_cfg = configspace.get_default_configuration()\n",
    "scenario = Scenario(configspace, deterministic=True, n_trials=n_iter_bayes)\n",
    "smac = HyperparameterOptimizationFacade(scenario, svc_objective_function)\n",
    "bayesOptimization_bestHyperParameter = smac.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie optymalnych hiperparametrów dla Bayes Optimization\n",
    "print(\"Optymalne hiperparametry:\", bayesOptimization_bestHyperParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis do plików historii tuningu dla Bayes Optimization\n",
    "for name, tunability_hisotry in zip(file_names, tunability_hisotry_list):\n",
    "    save_data_to_csv(pd.DataFrame(tunability_hisotry),\n",
    "                     f\"../Wyniki/SVC/BayesOptimization/{name}.csv\")\n",
    "    \n",
    "save_data_to_csv(pd.DataFrame(allDatasets_BO_tunability_history), f\"../Wyniki/SVC/BayesOptimization/allDatasets_tunability_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porownanie modeli dla hiperparametorw defaultowych, znaleznionych poprzez RandomSearch oraz Bayes Optimization\n",
    "randomSearch_Model = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', SVC(C=randomSearch_bestHyperParameter['param_model__C'].values[0],\n",
    "                            kernel=randomSearch_bestHyperParameter['param_model__kernel'].values[0],\n",
    "                            gamma=randomSearch_bestHyperParameter['param_model__gamma'].values[0], \n",
    "                            random_state=random_state, probability=True))])\n",
    "\n",
    "bayesOptimization_Model = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', SVC(C=bayesOptimization_bestHyperParameter['C'],\n",
    "                            kernel=bayesOptimization_bestHyperParameter['kernel'],\n",
    "                            gamma=bayesOptimization_bestHyperParameter['gamma'], \n",
    "                            random_state=random_state, probability=True))])\n",
    "\n",
    "default_Model = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', SVC(random_state=random_state, probability=True))])\n",
    "\n",
    "comparison = create_comparison_object()\n",
    "\n",
    "for X_train, y_train, X_test, y_test, filename in zip( X_train_list, y_train_list, X_test_list, y_test_list, file_names):\n",
    "    randomSearch_Model.fit(X_train, y_train)\n",
    "    bayesOptimization_Model.fit(X_train, y_train)\n",
    "    default_Model.fit(X_train, y_train)\n",
    "\n",
    "    randomSearch_Model_test_pred = randomSearch_Model.predict_proba(X_test)\n",
    "    bayesOptimization_Model_test_pred = bayesOptimization_Model.predict_proba(X_test)\n",
    "    default_Model_test_pred = default_Model.predict_proba(X_test)\n",
    "\n",
    "    randomSearch_Model_auc_test = roc_auc_score(y_test, randomSearch_Model_test_pred[:,1])\n",
    "    bayesOptimization_Model_auc_test = roc_auc_score(y_test, bayesOptimization_Model_test_pred[:,1])\n",
    "    default_Model_auc_test = roc_auc_score(y_test, default_Model_test_pred[:,1])\n",
    "    \n",
    "    comparison['dataset'].append(filename) \n",
    "    comparison['randomSearch_Model_auc_test'].append(randomSearch_Model_auc_test)\n",
    "    comparison['bayesOptimization_Model_auc_test'].append(bayesOptimization_Model_auc_test)  \n",
    "    comparison['default_Model_auc_test'].append(default_Model_auc_test)\n",
    "\n",
    "    print(f'filename: {filename}\\n')\n",
    "    print(f'randomSearch_Model_auc_test: {randomSearch_Model_auc_test}, bayesOptimization_Model_auc_test: {bayesOptimization_Model_auc_test}, default_Model_auc_test: {default_Model_auc_test}\\n')\n",
    "\n",
    "save_data_to_csv(pd.DataFrame(comparison), f\"../Wyniki/SVC/sampling_comparison.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
