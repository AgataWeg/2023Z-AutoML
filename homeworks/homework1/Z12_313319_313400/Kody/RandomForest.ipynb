{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from smac import HyperparameterOptimizationFacade, Scenario\n",
    "from ConfigSpace import Configuration, ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import UniformIntegerHyperparameter, CategoricalHyperparameter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from Utils.dataManagingUtils import fetch_openml_dataset, prepare_data, save_data_to_csv, create_randomForest_tuning_hisotry_object, create_randomForest_allDatasets_tuning_hisotry_object, create_comparison_object\n",
    "from Utils.pipelineUtils import create_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "set_config(transform_output = \"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja stałych użytych w metodach samplingu \n",
    "n_jobs=-1\n",
    "n_iter_randomSearch=450  # okolo 1h\n",
    "n_iter_bayes=150 # okolo 3h \n",
    "verbose=1\n",
    "random_state=42\n",
    "cv=5\n",
    "\n",
    "# Wartości hiperparametrów\n",
    "n_estimators_lower = 10\n",
    "n_estimators_upper = 230\n",
    "max_depth_lower = 1\n",
    "max_depth_upper = 15\n",
    "min_samples_split_lower = 1\n",
    "min_samples_split_upper = 15\n",
    "min_samples_leaf_lower = 1\n",
    "min_samples_leaf_upper = 10\n",
    "max_features = ['sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pobieranie danych\n",
    "m_t_beforePrepare = fetch_openml_dataset(44116)\n",
    "o_s_beforePrepare = fetch_openml_dataset(45560)\n",
    "b_m_beforePrepare = fetch_openml_dataset(44126)\n",
    "c_d_beforePrepare = fetch_openml_dataset(45024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obróbka Danych \n",
    "m_t_X, m_t_y = prepare_data(m_t_beforePrepare, 'class')\n",
    "o_s_X, o_s_y = prepare_data(o_s_beforePrepare, 'Revenue')\n",
    "b_m_X, b_m_y = prepare_data(b_m_beforePrepare, 'Class')\n",
    "c_d_X, c_d_y = prepare_data(c_d_beforePrepare, 'SeriousDlqin2yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział Danych \n",
    "m_t_X_train,   m_t_X_test, m_t_y_train, m_t_y_test = train_test_split(m_t_X , m_t_y,test_size=0.2)\n",
    "o_s_X_train,   o_s_X_test, o_s_y_train, o_s_y_test = train_test_split(o_s_X, o_s_y,test_size=0.2)\n",
    "b_m_X_train,   b_m_X_test, b_m_y_train, b_m_y_test = train_test_split(b_m_X, b_m_y,test_size=0.2)\n",
    "c_d_X_train,   c_d_X_test, c_d_y_train, c_d_y_test = train_test_split(c_d_X, c_d_y,test_size=0.2)\n",
    "\n",
    "X_train_list = [ m_t_X_train, o_s_X_train, b_m_X_train, c_d_X_train]\n",
    "y_train_list = [ m_t_y_train, o_s_y_train, b_m_y_train, c_d_y_train]\n",
    "X_test_list = [ m_t_X_test, o_s_X_test, b_m_X_test, c_d_X_test]\n",
    "y_test_list = [ m_t_y_test, o_s_y_test, b_m_y_test, c_d_y_test]\n",
    "file_names = [\"m_t_tuning_history\", \"o_s_tuning_history\", \"b_m_tuning_history\",\"c_d_tuning_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja tabel służących do przechowywania informacji o histori tuningu dla random Search, biorąc pod uwagę wszystkie datasety\n",
    "allDatasets_randomSearch_tunability_history = create_randomForest_allDatasets_tuning_hisotry_object()\n",
    "helper = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier optymalizacja hiperparametrow uzywajac RandomizedSearchCV\n",
    "param_space = {\n",
    "    'model__n_estimators': np.linspace(n_estimators_lower, n_estimators_upper, n_estimators_upper - n_estimators_lower).astype(int),\n",
    "    'model__max_depth': np.linspace(max_depth_lower, max_depth_upper, max_depth_upper- max_depth_lower).astype(int),\n",
    "    'model__min_samples_split': np.linspace(min_samples_split_lower, min_samples_split_upper, min_samples_split_upper - min_samples_split_lower).astype(int),\n",
    "    'model__min_samples_leaf': np.linspace(min_samples_leaf_lower, min_samples_leaf_upper, min_samples_leaf_upper - min_samples_leaf_lower).astype(int),\n",
    "    'model__max_features': max_features \n",
    "}\n",
    "\n",
    "randomForestClassifier_pipeline = Pipeline([\n",
    "    ('preprocessing', create_column_transformer()),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=randomForestClassifier_pipeline,\n",
    "    param_distributions=param_space,\n",
    "    n_jobs=n_jobs,\n",
    "    n_iter=n_iter_randomSearch,\n",
    "    verbose=verbose,\n",
    "    random_state=random_state,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "\n",
    "for file_name, X_train, y_train in zip(file_names, X_train_list, y_train_list):\n",
    "    random_search.fit(X_train, y_train)\n",
    "    cs_results = pd.DataFrame(random_search.cv_results_)\n",
    "    helper[f'{file_name}']=cs_results['mean_test_score']\n",
    "    save_data_to_csv(cs_results, f\"../Wyniki/RandomForestClassifier/RandomSearch/{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenie optymalnych hiperparametrow dla random search\n",
    "mean_column = helper.mean(axis=1)\n",
    "std_column = helper.std(axis=1)\n",
    "\n",
    "for i in range(len(cs_results)):\n",
    "    allDatasets_randomSearch_tunability_history['param_model__n_estimators'].append(cs_results['param_model__n_estimators'][i])\n",
    "    allDatasets_randomSearch_tunability_history['param_model__min_samples_split'].append(cs_results['param_model__min_samples_split'][i])\n",
    "    allDatasets_randomSearch_tunability_history['param_model__min_samples_leaf'].append(cs_results['param_model__min_samples_leaf'][i])\n",
    "    allDatasets_randomSearch_tunability_history['param_model__max_features'].append(cs_results['param_model__max_features'][i])\n",
    "    allDatasets_randomSearch_tunability_history['param_model__max_depth'].append(cs_results['param_model__max_depth'][i])\n",
    "    allDatasets_randomSearch_tunability_history['mean_all_datasets_test_score'].append(mean_column[i])\n",
    "    allDatasets_randomSearch_tunability_history['std_all_datasets_test_score'].append(std_column[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie optymalnych hiperparametrów dla Random Search\n",
    "allDatasets_randomSearch_tunability_history = pd.DataFrame(allDatasets_randomSearch_tunability_history)\n",
    "max_value = allDatasets_randomSearch_tunability_history['mean_all_datasets_test_score'].max()\n",
    "randomSearch_bestHyperParameter = allDatasets_randomSearch_tunability_history[allDatasets_randomSearch_tunability_history['mean_all_datasets_test_score'] == max_value]\n",
    "print(\"Optymalne hiperparametry:\", randomSearch_bestHyperParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis do plików historii tuningu dla Random Search \n",
    "save_data_to_csv(allDatasets_randomSearch_tunability_history, f\"../Wyniki/RandomForestClassifier/RandomSearch/allDatasets_tunability_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja tabel służących do przechowywania informacji o histori tuningu dla Bayes Optimization\n",
    "m_t_tunability_history = create_randomForest_tuning_hisotry_object(cv)\n",
    "o_s_tunability_history = create_randomForest_tuning_hisotry_object(cv)\n",
    "b_m_tunability_history = create_randomForest_tuning_hisotry_object(cv)\n",
    "c_d_tunability_history = create_randomForest_tuning_hisotry_object(cv)\n",
    "tunability_hisotry_list = [m_t_tunability_history,o_s_tunability_history,b_m_tunability_history, c_d_tunability_history]\n",
    "\n",
    "# Definicja tabel służących do przechowywania informacji o histori tuningu dla Bayes Optimization, biorąc pod uwagę wszystkie datasety\n",
    "allDatasets_BO_tunability_history = create_randomForest_allDatasets_tuning_hisotry_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicja tabel służących do przechowywania informacji o historii tuningu dla Bayes Optimization\n",
    "def randomForest_objective_function(config: Configuration, seed :int):\n",
    "    all_scores = []\n",
    "    n_estimators = config['n_estimators']\n",
    "    max_depth = config['max_depth']\n",
    "    min_samples_split = config['min_samples_split']\n",
    "    min_samples_leaf = config['min_samples_leaf']\n",
    "    max_features = config['max_features']\n",
    "    print(f\"n_estimators:{n_estimators}, max_depth:{max_depth}, min_samples_split:{min_samples_split}, min_samples_leaf:{min_samples_leaf}, max_features:{max_features}\\n\")\n",
    "    \n",
    "    allDatasets_BO_tunability_history['param_model__n_estimators'].append(n_estimators)\n",
    "    allDatasets_BO_tunability_history['param_model__min_samples_split'].append(min_samples_split)  \n",
    "    allDatasets_BO_tunability_history['param_model__min_samples_leaf'].append(min_samples_leaf)  \n",
    "    allDatasets_BO_tunability_history['param_model__max_features'].append(max_features)  \n",
    "    allDatasets_BO_tunability_history['param_model__max_depth'].append(max_depth)\n",
    "\n",
    "    for X_train, y_train, tunability_hisotry in zip(X_train_list, y_train_list, tunability_hisotry_list):\n",
    "        tunability_hisotry['param_model__n_estimators'].append(n_estimators)\n",
    "        tunability_hisotry['param_model__min_samples_split'].append(min_samples_split)  \n",
    "        tunability_hisotry['param_model__min_samples_leaf'].append(min_samples_leaf)  \n",
    "        tunability_hisotry['param_model__max_features'].append(max_features)  \n",
    "        tunability_hisotry['param_model__max_depth'].append(max_depth) \n",
    "\n",
    "        randomForestClassifier_pipeline = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                             max_depth=max_depth,\n",
    "                                             min_samples_split=min_samples_split,\n",
    "                                             min_samples_leaf=min_samples_leaf, \n",
    "                                             max_features=max_features,\n",
    "                                             random_state=seed))])\n",
    "        scores = cross_val_score(randomForestClassifier_pipeline, X_train, y_train, scoring='roc_auc', cv=cv)\n",
    "        for i in range(cv):\n",
    "            tunability_hisotry[f'split{i}_test_score'].append(scores[i])\n",
    "        tunability_hisotry['mean_test_score'].append(np.mean(scores))  \n",
    "        tunability_hisotry['std_test_score'].append(np.std(scores)) \n",
    "        all_scores.extend(scores)\n",
    "    \n",
    "    all_scores_mean = np.mean(all_scores)\n",
    "    all_scores_std = np.std(all_scores)\n",
    "    allDatasets_BO_tunability_history['mean_all_datasets_test_score'].append(all_scores_mean)  \n",
    "    allDatasets_BO_tunability_history['std_all_datasets_test_score'].append(all_scores_std)    \n",
    "    print(f\"all_scores_mean:{all_scores_mean}, all_scores_std:{all_scores_std}\\n\")\n",
    "    return -all_scores_mean\n",
    "\n",
    "configspace = ConfigurationSpace()\n",
    "configspace.add_hyperparameter(UniformIntegerHyperparameter('n_estimators', lower=n_estimators_lower, upper=n_estimators_upper))\n",
    "configspace.add_hyperparameter(UniformIntegerHyperparameter('max_depth', lower= max_depth_lower, upper=max_depth_upper))\n",
    "configspace.add_hyperparameter(UniformIntegerHyperparameter('min_samples_split', lower=min_samples_split_lower, upper=min_samples_split_upper))\n",
    "configspace.add_hyperparameter(UniformIntegerHyperparameter('min_samples_leaf', lower=min_samples_leaf_lower, upper=min_samples_leaf_upper))\n",
    "configspace.add_hyperparameter(CategoricalHyperparameter('max_features',max_features))\n",
    "\n",
    "default_cfg = configspace.get_default_configuration()\n",
    "scenario = Scenario(configspace, deterministic=True, n_trials=n_iter_bayes)\n",
    "smac = HyperparameterOptimizationFacade(scenario, randomForest_objective_function)\n",
    "bayesOptimization_bestHyperParameter = smac.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie optymalnych hiperparametrów dla Bayes Optimization\n",
    "print(\"Optymalne hiperparametry:\", bayesOptimization_bestHyperParameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis do plików historii tuningu dla Bayes Optimization\n",
    "for name, tunability_hisotry in zip(file_names, tunability_hisotry_list):\n",
    "    save_data_to_csv(pd.DataFrame(tunability_hisotry),\n",
    "                     f\"../Wyniki/RandomForestClassifier/BayesOptimization/{name}.csv\")\n",
    "    \n",
    "save_data_to_csv(pd.DataFrame(allDatasets_BO_tunability_history), f\"../Wyniki/RandomForestClassifier/BayesOptimization/allDatasets_tunability_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porownanie modeli dla hiperparametorw defaultowych, znaleznionych poprzez RandomSearch oraz Bayes Optimization\n",
    "randomSearch_Model = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', RandomForestClassifier(n_estimators=randomSearch_bestHyperParameter['param_model__n_estimators'].values[0],\n",
    "                                             max_depth=randomSearch_bestHyperParameter['param_model__max_depth'].values[0],\n",
    "                                             min_samples_split=randomSearch_bestHyperParameter['param_model__min_samples_split'].values[0],\n",
    "                                             min_samples_leaf=randomSearch_bestHyperParameter['param_model__min_samples_leaf'].values[0], \n",
    "                                             max_features=randomSearch_bestHyperParameter['param_model__max_features'].values[0],\n",
    "                                             random_state=random_state))])\n",
    "\n",
    "bayesOptimization_Model = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', RandomForestClassifier(n_estimators=bayesOptimization_bestHyperParameter['n_estimators'],\n",
    "                                             max_depth=bayesOptimization_bestHyperParameter['max_depth'],\n",
    "                                             min_samples_split=bayesOptimization_bestHyperParameter['min_samples_split'],\n",
    "                                             min_samples_leaf=bayesOptimization_bestHyperParameter['min_samples_leaf'], \n",
    "                                             max_features=bayesOptimization_bestHyperParameter['max_features'],\n",
    "                                             random_state=random_state))])\n",
    "\n",
    "default_Model = Pipeline([\n",
    "            ('preprocessing', create_column_transformer()),\n",
    "            ('model', RandomForestClassifier(random_state=random_state))])\n",
    "\n",
    "comparison = create_comparison_object()\n",
    "\n",
    "for X_train, y_train, X_test, y_test, filename in zip( X_train_list, y_train_list, X_test_list, y_test_list, file_names):\n",
    "    randomSearch_Model.fit(X_train, y_train)\n",
    "    bayesOptimization_Model.fit(X_train, y_train)\n",
    "    default_Model.fit(X_train, y_train)\n",
    "\n",
    "    randomSearch_Model_test_pred = randomSearch_Model.predict_proba(X_test)\n",
    "    bayesOptimization_Model_test_pred = bayesOptimization_Model.predict_proba(X_test)\n",
    "    default_Model_test_pred = default_Model.predict_proba(X_test)\n",
    "\n",
    "    randomSearch_Model_auc_test = roc_auc_score(y_test, randomSearch_Model_test_pred[:,1])\n",
    "    bayesOptimization_Model_auc_test = roc_auc_score(y_test, bayesOptimization_Model_test_pred[:,1])\n",
    "    default_Model_auc_test = roc_auc_score(y_test, default_Model_test_pred[:,1])\n",
    "    \n",
    "    comparison['dataset'].append(filename) \n",
    "    comparison['randomSearch_Model_auc_test'].append(randomSearch_Model_auc_test)\n",
    "    comparison['bayesOptimization_Model_auc_test'].append(bayesOptimization_Model_auc_test)  \n",
    "    comparison['default_Model_auc_test'].append(default_Model_auc_test)\n",
    "\n",
    "    print(f'filename: {filename}\\n')\n",
    "    print(f'randomSearch_Model_auc_test: {randomSearch_Model_auc_test}, bayesOptimization_Model_auc_test: {bayesOptimization_Model_auc_test}, default_Model_auc_test: {default_Model_auc_test}\\n')\n",
    "\n",
    "save_data_to_csv(pd.DataFrame(comparison), f\"../Wyniki/RandomForestClassifier/sampling_comparison.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
