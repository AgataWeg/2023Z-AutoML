{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "datasets = {\n",
    "    'iris': load_iris(return_X_y=True),\n",
    "    'digits': load_digits(return_X_y=True),\n",
    "    'wine': load_wine(return_X_y=True),\n",
    "    'breast_cancer': load_breast_cancer(return_X_y=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': list(range(2, 30)),\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'p': [1, 2]\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': list(range(100, 2000, 50)),\n",
    "            'max_depth': list(range(10, 110, 10)),\n",
    "            'min_samples_split': list(range(2, 10)),\n",
    "            'min_samples_leaf': list(range(1, 10)),\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': list(range(50, 1000, 50)),\n",
    "            'max_depth': list(range(1, 10)),\n",
    "            'learning_rate': np.linspace(0.01, 0.3, num=10).tolist(),\n",
    "            'subsample': np.linspace(0.5, 1, num=10).tolist(),\n",
    "            'colsample_bytree': np.linspace(0.5, 1, num=10).tolist()\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished KNN on iris\n",
      "Finished RandomForest on iris\n",
      "Finished XGBoost on iris\n",
      "Finished KNN on digits\n",
      "Finished RandomForest on digits\n",
      "Finished XGBoost on digits\n",
      "Finished KNN on wine\n",
      "Finished RandomForest on wine\n",
      "Finished XGBoost on wine\n",
      "Finished KNN on breast_cancer\n",
      "Finished RandomForest on breast_cancer\n",
      "Finished XGBoost on breast_cancer\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "best_results = []\n",
    "for dataset_name, data in datasets.items():\n",
    "    X, y = data\n",
    "    \n",
    "    for algorithm_name, algo in models.items():\n",
    "        clf = RandomizedSearchCV(algo['model'], algo['params'], n_iter=50, cv=5, random_state=42, scoring='accuracy')\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        # Get the results of the randomized search\n",
    "        cv_results = clf.cv_results_\n",
    "        \n",
    "        for i in range(clf.n_iter):\n",
    "            results.append({\n",
    "                'dataset': dataset_name,\n",
    "                'model': algorithm_name,\n",
    "                'score': abs(round(cv_results['mean_test_score'][i], 4)),\n",
    "                'hyperparameters': cv_results['params'][i],\n",
    "                'iteration': i\n",
    "            })\n",
    "        \n",
    "        # Save the best result from each fit\n",
    "        best_results.append({\n",
    "            'dataset': dataset_name,\n",
    "            'model': algorithm_name,\n",
    "            'score': abs(round(clf.best_score_, 4)),\n",
    "            'hyperparameters': clf.best_params_,\n",
    "            'iteration': np.argmax(cv_results['mean_test_score'])\n",
    "        })\n",
    "        \n",
    "        print(f'Finished {algorithm_name} on {dataset_name}')\n",
    "\n",
    "# Convert the results to a DataFrame for easier manipulation\n",
    "df_history = pd.DataFrame(results)\n",
    "df_best = pd.DataFrame(best_results)\n",
    "\n",
    "# Save to file\n",
    "df_history.to_csv('Wyniki/random-search-history.csv', index=False)\n",
    "df_best.to_csv('Wyniki/random-search-best.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
